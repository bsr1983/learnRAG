#!/usr/bin/env python3
"""
éªŒè¯ LLM é…ç½®è„šæœ¬
æ£€æŸ¥çŽ¯å¢ƒå˜é‡å’Œ LLM å®¢æˆ·ç«¯æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from dotenv import load_dotenv

# åŠ è½½ .env æ–‡ä»¶
load_dotenv()

print("=" * 60)
print("LLM é…ç½®éªŒè¯")
print("=" * 60)
print()

# 1. æ£€æŸ¥çŽ¯å¢ƒå˜é‡
print("1. æ£€æŸ¥çŽ¯å¢ƒå˜é‡:")
print("-" * 60)

providers = {
    "doubao": "DOUBAO_API_KEY",
    "openai": "OPENAI_API_KEY",
    "qwen": "DASHSCOPE_API_KEY",
    "ernie": "ERNIE_API_KEY",
    "zhipu": "ZHIPU_API_KEY"
}

llm_provider = os.getenv("LLM_PROVIDER", "not set")
print(f"LLM_PROVIDER: {llm_provider}")

for provider, env_var in providers.items():
    value = os.getenv(env_var)
    if value:
        # åªæ˜¾ç¤ºå‰10ä¸ªå­—ç¬¦å’ŒåŽ5ä¸ªå­—ç¬¦ï¼Œä¿æŠ¤éšç§
        masked = value[:10] + "..." + value[-5:] if len(value) > 15 else "***"
        print(f"  âœ… {env_var}: {masked}")
    else:
        print(f"  âŒ {env_var}: æœªè®¾ç½®")

print()

# 2. å°è¯•åˆå§‹åŒ– LLM å®¢æˆ·ç«¯
print("2. æµ‹è¯• LLM å®¢æˆ·ç«¯åˆå§‹åŒ–:")
print("-" * 60)

try:
    from llm.llm_client import get_llm_client
    
    # å¦‚æžœè®¾ç½®äº† LLM_PROVIDERï¼Œä½¿ç”¨å®ƒï¼›å¦åˆ™å°è¯• doubao
    provider = llm_provider if llm_provider != "not set" else "doubao"
    
    print(f"å°è¯•ä½¿ç”¨æä¾›å•†: {provider}")
    client = get_llm_client(provider=provider)
    print(f"âœ… LLM å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    print(f"   æä¾›å•†: {provider}")
    print(f"   æ¨¡åž‹: {client.model_name}")
    print(f"   Base URL: {client.base_url}")
    
except Exception as e:
    print(f"âŒ LLM å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
    print()
    print("å¯èƒ½çš„åŽŸå› :")
    print("  1. API Key æœªè®¾ç½®æˆ–æ ¼å¼ä¸æ­£ç¡®")
    print("  2. æä¾›å•†åç§°é”™è¯¯")
    print("  3. ç½‘ç»œè¿žæŽ¥é—®é¢˜")
    sys.exit(1)

print()

# 3. æµ‹è¯• LLM è°ƒç”¨
print("3. æµ‹è¯• LLM API è°ƒç”¨:")
print("-" * 60)

try:
    test_prompt = "è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±"
    print(f"æµ‹è¯•æç¤º: {test_prompt}")
    print("æ­£åœ¨è°ƒç”¨ LLM...")
    
    response = client.generate(
        prompt=test_prompt,
        temperature=0.7,
        max_tokens=100
    )
    
    print(f"âœ… LLM è°ƒç”¨æˆåŠŸ!")
    print(f"å“åº”: {response}")
    
except Exception as e:
    print(f"âŒ LLM è°ƒç”¨å¤±è´¥: {e}")
    print()
    print("å¯èƒ½çš„åŽŸå› :")
    print("  1. API Key æ— æ•ˆæˆ–å·²è¿‡æœŸ")
    print("  2. API ç«¯ç‚¹ä¸å¯è®¿é—®")
    print("  3. æ¨¡åž‹åç§°ä¸æ­£ç¡®")
    print("  4. ç½‘ç»œè¿žæŽ¥é—®é¢˜")
    sys.exit(1)

print()
print("=" * 60)
print("âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼LLM é…ç½®æ­£ç¡®")
print("=" * 60)
print()
print("ðŸ’¡ æç¤º:")
print("  å¦‚æžœçŽ¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•ä¹‹ä¸€:")
print()
print("  æ–¹æ³•ä¸€ï¼šåœ¨å½“å‰ç»ˆç«¯è®¾ç½®ï¼ˆä¸´æ—¶ï¼‰")
print("    export DOUBAO_API_KEY=your_api_key")
print("    export LLM_PROVIDER=doubao")
print()
print("  æ–¹æ³•äºŒï¼šä½¿ç”¨ .env æ–‡ä»¶ï¼ˆæŽ¨èï¼‰")
print("    1. åˆ›å»º .env æ–‡ä»¶ï¼šcp .env.example .env")
print("    2. ç¼–è¾‘ .envï¼Œè®¾ç½® DOUBAO_API_KEY å’Œ LLM_PROVIDER")
print()
print("  æ–¹æ³•ä¸‰ï¼šæ·»åŠ åˆ° ~/.zshrcï¼ˆæ°¸ä¹…ï¼‰")
print("    echo 'export DOUBAO_API_KEY=your_api_key' >> ~/.zshrc")
print("    echo 'export LLM_PROVIDER=doubao' >> ~/.zshrc")
print("    source ~/.zshrc")

